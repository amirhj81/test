# =========================================================
# summary_lmstudio_multithread.py
# ÙÙ‚Ø· DuckDuckGo + Selenium + ThreadPoolExecutor
# =========================================================
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

import re
import time
import functools
from concurrent.futures import ThreadPoolExecutor, as_completed

# ---------- Selenium ----------
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import WebDriverException
from bs4 import BeautifulSoup
from webdriver_manager.chrome import ChromeDriverManager

# ---------- DuckDuckGo ----------
from ddgs import DDGS        # pip install ddgs

# =========================================================
# State
# =========================================================
class State(TypedDict):
    messages: list
    need_search: str

# =========================================================
# Ø§ØªØµØ§Ù„ Ø¨Ù‡ LM Studio
# =========================================================
llm = ChatOpenAI(
    model="gemma-3-4b-it@q4_k_m",
    openai_api_base="http://localhost:4050/v1",
    openai_api_key="lmstudio",
    temperature=0.1
)

# =========================================================
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# =========================================================
def _selenium_fetch_single(url: str, max_chars: int = 4000) -> str:
    """ÛŒÚ© URL Ø±Ø§ Ø¨Ø§ Selenium headless Ø¨Ø§Ø² Ú©Ø±Ø¯Ù‡ Ùˆ Ù…ØªÙ† ØªÙ…ÛŒØ² Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    chrome_opts = Options()
    chrome_opts.add_argument("--headless=new")
    chrome_opts.add_argument("--disable-gpu")
    chrome_opts.add_argument("--no-sandbox")
    chrome_opts.add_argument("--window-size=1920,3000")
    chrome_opts.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/125 Safari/537.36"
    )

    driver = None
    try:
        driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()),
            options=chrome_opts
        )
        driver.get(url)

        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.2)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        html = driver.page_source
        soup = BeautifulSoup(html, "lxml")
        for tag in soup(["script", "style", "nav", "footer", "aside", "header", "noscript"]):
            tag.extract()

        text = soup.get_text(separator=" ", strip=True)
        text = re.sub(r"\s+", " ", text)[:max_chars]
        return f"Ù…Ù†Ø¨Ø¹: {url}\n{text}"

    except WebDriverException as e:
        return f"[Ø®Ø·Ø§ Ø¯Ø± Selenium Ø¨Ø±Ø§ÛŒ {url}: {e}]"
    finally:
        if driver:
            driver.quit()


def _search_links(query: str, num: int = 3) -> list[str]:
    """ÙÙ‚Ø· Ø§Ø² DuckDuckGo Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯."""
    try:
        return [item["href"] for item in DDGS().text(query, region='ir', max_results=num)]
    except Exception as e:
        print(f"âš ï¸ DDGS Ø®Ø·Ø§: {e}")
        return []

# =========================================================
# Nodes
# =========================================================
def check_need_search(state: State):
    user_msg = state["messages"][-1].content
    response = llm.invoke([
        HumanMessage(
            content=f"Ø¢ÛŒØ§ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ø²ÛŒØ± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø§ÛŒÙ†ØªØ±Ù†Øª Ù‡Ø³ØªØŸ "
                    f"ÙÙ‚Ø· Ø¬ÙˆØ§Ø¨ 'Ø¨Ù„Ù‡' ÛŒØ§ 'Ø®ÛŒØ±'.\n\nÙ…ÙˆØ¶ÙˆØ¹: {user_msg}"
        )
    ])
    return {"need_search": "Ø¨Ù„Ù‡" if "Ø¨Ù„Ù‡" in response.content else "Ø®ÛŒØ±"}


def search(state: State):
    """
    1) Ø¹Ø¨Ø§Ø±Øª Ø¨Ù‡ÛŒÙ†Ù‡ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯
    2) ÙÙ‚Ø· Ø§Ø² DuckDuckGo Ù„ÛŒÙ†Ú© Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
    3) Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ø§ multi-thread Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    """
    user_msg = state["messages"][-1].content

    # 1) Ø¹Ø¨Ø§Ø±Øª Ø¨Ù‡ÛŒÙ†Ù‡
    optimized_query_msg = HumanMessage(
        content=f"Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ØŒ ØªÙ†Ù‡Ø§ Ú†Ù†Ø¯ Ú©Ù„Ù…Ù‡Ù” Ú©Ù„ÛŒØ¯ÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¯Ø§Ø±Ù†Ø¯ Ø¨Ù†ÙˆÛŒØ³ØŒ "
                f"Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡:\n{user_msg}"
    )
    optimized_query = llm.invoke([optimized_query_msg]).content.strip().splitlines()[0]
    print(f"ğŸ” Ø¹Ø¨Ø§Ø±Øª Ø¬Ø³ØªØ¬ÙˆÛŒ DuckDuckGo: {optimized_query}")

    # 2) Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø§Ø² DuckDuckGo
    links = _search_links(optimized_query, 3)

    # 3) Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ
    full_texts = []
    if links:
        fetch = functools.partial(_selenium_fetch_single, max_chars=4000)
        with ThreadPoolExecutor(max_workers=min(3, len(links))) as executor:
            future_to_url = {executor.submit(fetch, url): url for url in links}
            for i, future in enumerate(as_completed(future_to_url), 1):
                url = future_to_url[future]
                try:
                    text = future.result()
                    full_texts.append(text)
                    print(f"[{i}/{len(links)}] Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: {url}")
                except Exception as e:
                    full_texts.append(f"[Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {url}: {e}]")

    combined_text = "\n\n".join(full_texts).strip()
    if not combined_text:
        combined_text = f"Ù‡ÛŒÚ† Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø§Ø² Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø±Ø§ÛŒ '{user_msg}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

    # 4) ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ
    final_msg = HumanMessage(
        content=f" Ù…Ø·Ù…Ø¹Ù† Ø´Ùˆ Ú©Ù‡ Ø¬ÙˆØ§Ø¨ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø®Ù„Ø§ØµÙ‡ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ±ØŒ ÛŒÚ© Ù…ØªÙ† ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ùˆ Ù…Ù†Ø³Ø¬Ù… Ø¨Ù†ÙˆÛŒØ³ "
                f"(Ú©Ù…ØªØ±ÛŒÙ† Ø­Ø§Ù„Øª Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø­Ø¯Ø§Ú©Ø«Ø± Û³-Ûµ Ø®Ø·):\n\n{combined_text}"
    )
    final_response = llm.invoke([final_msg])
    return {"messages": state["messages"] + [final_response]}


def llm_only(state: State):
    user_msg = state["messages"][-1].content
    response = llm.invoke([HumanMessage(content=f"Ù…ÙˆØ¶ÙˆØ¹ Ø²ÛŒØ± Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡:\n\n{user_msg}")])
    return {"messages": state["messages"] + [response]}

# =========================================================
# Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù
# =========================================================
graph_builder = StateGraph(State)
graph_builder.add_node("check_need_search", check_need_search)
graph_builder.add_node("search", search)
graph_builder.add_node("llm_only", llm_only)

graph_builder.set_entry_point("check_need_search")
graph_builder.add_conditional_edges(
    "check_need_search",
    lambda state: "search" if state["need_search"] == "Ø¨Ù„Ù‡" else "llm_only",
    {"search": "search", "llm_only": "llm_only"}
)
graph_builder.add_edge("search", END)
graph_builder.add_edge("llm_only", END)

graph = graph_builder.compile()

# =========================================================
# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
# =========================================================
if __name__ == "__main__":
    topic = input("Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ")
    result = graph.invoke({"messages": [HumanMessage(content=topic)], "need_search": ""})
    print("\nğŸ“Œ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:\n")
    for m in result["messages"]:
        print(m.content)